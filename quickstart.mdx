---
title: Quickstart
description: Get started with Foil in 5 minutes
---

# Quickstart

This guide will get you from zero to traced AI calls in under 5 minutes.

## Prerequisites

- A Foil account ([sign up here](https://app.getfoil.ai))
- An API key from the Foil dashboard
- Node.js 18+ or Python 3.8+

## Step 1: Install the SDK

<Tabs>
  <Tab title="JavaScript">
    ```bash
    npm install @getfoil/foil-js
    ```
  </Tab>
  <Tab title="Python">
    ```bash
    pip install foil-sdk
    ```
  </Tab>
</Tabs>

## Step 2: Initialize Foil

<Tabs>
  <Tab title="JavaScript (OpenTelemetry)">
    The easiest way to get started - one line and all your LLM calls are traced automatically.

    ```javascript
    const { Foil } = require('@getfoil/foil-js/otel');

    // Initialize at the top of your app
    Foil.init({
      apiKey: process.env.FOIL_API_KEY,
      agentName: 'my-first-agent',
    });
    ```
  </Tab>
  <Tab title="JavaScript (Manual)">
    For more control over what gets traced.

    ```javascript
    const { createFoilTracer } = require('@getfoil/foil-js');

    const tracer = createFoilTracer({
      apiKey: process.env.FOIL_API_KEY,
      agentName: 'my-first-agent',
    });
    ```
  </Tab>
  <Tab title="Python">
    ```python
    from foil import Foil
    import os

    foil = Foil(api_key=os.environ['FOIL_API_KEY'])
    ```
  </Tab>
</Tabs>

## Step 3: Trace Your First Call

<Tabs>
  <Tab title="JavaScript (OpenTelemetry)">
    With OpenTelemetry, your LLM calls are traced automatically - no extra code needed!

    ```javascript
    const { Foil } = require('@getfoil/foil-js/otel');
    const OpenAI = require('openai');

    // Initialize Foil (do this once at app startup)
    Foil.init({
      apiKey: process.env.FOIL_API_KEY,
      agentName: 'my-first-agent',
    });

    // Use OpenAI as normal - it's automatically traced!
    const openai = new OpenAI();

    const response = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages: [{ role: 'user', content: 'What is the capital of France?' }],
    });

    console.log(response.choices[0].message.content); // "Paris"
    // ↑ This call was automatically traced to Foil!
    ```
  </Tab>
  <Tab title="JavaScript (Manual)">
    Manual tracing gives you full control over span creation.

    ```javascript
    const { createFoilTracer, SpanKind } = require('@getfoil/foil-js');
    const OpenAI = require('openai');

    const openai = new OpenAI();
    const tracer = createFoilTracer({
      apiKey: process.env.FOIL_API_KEY,
      agentName: 'my-first-agent',
    });

    // Wrap your AI logic in a trace
    const result = await tracer.trace(async (ctx) => {
      // Start an LLM span
      const span = await ctx.startSpan(SpanKind.LLM, 'gpt-4o', {
        input: 'What is the capital of France?',
      });

      // Make the API call
      const response = await openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [{ role: 'user', content: 'What is the capital of France?' }],
      });

      // End the span with results
      await span.end({
        output: response.choices[0].message.content,
        tokens: {
          prompt: response.usage.prompt_tokens,
          completion: response.usage.completion_tokens,
          total: response.usage.total_tokens,
        },
      });

      return response.choices[0].message.content;
    }, { name: 'capital-query' });

    console.log(result); // "Paris"
    ```
  </Tab>
  <Tab title="Python">
    ```python
    from openai import OpenAI
    from foil import Foil
    import os

    client = OpenAI()
    foil = Foil(api_key=os.environ['FOIL_API_KEY'])

    # Wrap OpenAI client - all calls automatically traced
    wrapped_client = foil.wrap_openai(client)

    # Make the API call - automatically traced
    response = wrapped_client.chat.completions.create(
        model='gpt-4o',
        messages=[{'role': 'user', 'content': 'What is the capital of France?'}]
    )

    print(response.choices[0].message.content)  # "Paris"
    ```
  </Tab>
</Tabs>

## Step 4: View Your Trace

1. Go to the [Foil Dashboard](https://app.getfoil.ai)
2. Navigate to **Traces**
3. Click on your trace to see the full span details

You'll see:
- The input and output of your LLM call
- Token usage breakdown
- Latency metrics
- Any errors or warnings

## What's Next?

<CardGroup cols={2}>
  <Card title="OpenTelemetry Integration" icon="circle-nodes" href="/sdks/javascript/opentelemetry">
    Deep dive into auto-instrumentation
  </Card>
  <Card title="Manual Tracing" icon="code" href="/sdks/javascript/tracing">
    Full control with custom spans
  </Card>
  <Card title="Set Up Alerts" icon="bell" href="/features/alerting">
    Get notified when issues occur
  </Card>
  <Card title="Record Feedback" icon="thumbs-up" href="/concepts/signals">
    Capture user feedback on your AI outputs
  </Card>
</CardGroup>

<Tip>
  **More examples**: Browse complete, runnable examples at [github.com/getfoil/foil-examples](https://github.com/getfoil/foil-examples) — including OTEL auto-instrumentation, custom evaluations, semantic search, and real-world agent scenarios.
</Tip>

## Complete Example

Here's a full working example you can copy and run:

<Tabs>
  <Tab title="JavaScript">
    ```javascript
    // app.js
    const { Foil } = require('@getfoil/foil-js/otel');
    const OpenAI = require('openai');

    // Initialize Foil at startup
    Foil.init({
      apiKey: process.env.FOIL_API_KEY,
      agentName: 'quickstart-agent',
    });

    async function main() {
      const openai = new OpenAI();

      // All OpenAI calls are automatically traced
      const response = await openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          { role: 'system', content: 'You are a helpful assistant.' },
          { role: 'user', content: 'Write a haiku about programming.' },
        ],
      });

      console.log(response.choices[0].message.content);

      // Flush traces before exit
      await Foil.flush();
    }

    main();
    ```

    Run it:
    ```bash
    FOIL_API_KEY=your-key OPENAI_API_KEY=your-key node app.js
    ```
  </Tab>
  <Tab title="Python">
    ```python
    # app.py
    from openai import OpenAI
    from foil import Foil
    import os

    foil = Foil(api_key=os.environ['FOIL_API_KEY'])
    client = foil.wrap_openai(OpenAI())

    response = client.chat.completions.create(
        model='gpt-4o',
        messages=[
            {'role': 'system', 'content': 'You are a helpful assistant.'},
            {'role': 'user', 'content': 'Write a haiku about programming.'},
        ]
    )

    print(response.choices[0].message.content)
    ```

    Run it:
    ```bash
    FOIL_API_KEY=your-key OPENAI_API_KEY=your-key python app.py
    ```
  </Tab>
</Tabs>
