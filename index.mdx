---
title: Introduction
description: Monitor, debug, and improve your AI agents with Foil
---

# Welcome to Foil

Foil is an observability platform purpose-built for AI applications. Get complete visibility into your LLM calls, agent workflows, and AI pipelines with distributed tracing, real-time alerting, and actionable analytics.

## Why Foil?

Building AI applications is hard. Debugging them is harder. Foil gives you the tools to understand what your AI is doing, why it's failing, and how to make it better.

<CardGroup cols={2}>
  <Card title="Distributed Tracing" icon="diagram-project">
    Track every LLM call, tool execution, and agent step with full context and parent-child relationships.
  </Card>
  <Card title="Real-time Alerting" icon="bell">
    Get notified instantly when your AI hallucinates, gets stuck, or produces low-quality outputs.
  </Card>
  <Card title="Cost Analytics" icon="chart-line">
    Monitor token usage, latency, and costs across all your models and agents.
  </Card>
  <Card title="Custom Signals" icon="signal">
    Track user feedback, quality scores, and custom metrics tied to your traces.
  </Card>
</CardGroup>

## How It Works

<Steps>
  <Step title="Install the SDK">
    Add the Foil SDK to your project with npm or pip.
    ```bash
    npm install @foil-ai/sdk
    ```
  </Step>
  <Step title="Instrument Your Code">
    Wrap your AI calls with Foil's tracer to capture every interaction.
    ```javascript
    const tracer = createFoilTracer({
      apiKey: 'your-api-key',
      agentName: 'my-agent'
    });

    await tracer.trace(async (ctx) => {
      // Your AI logic here
    });
    ```
  </Step>
  <Step title="View in Dashboard">
    See your traces, metrics, and alerts in the Foil dashboard.
  </Step>
</Steps>

## Features

### Traces & Spans

Every AI interaction is captured as a **trace** containing multiple **spans**. Spans represent individual operations like LLM calls, tool executions, or retrieval steps. Foil automatically tracks:

- Input and output content
- Token usage (prompt, completion, total)
- Latency and time-to-first-token
- Errors and status codes
- Custom metadata

### Intelligent Alerting

Foil uses LLM analysis to detect issues that traditional monitoring misses:

- **Hallucination Detection** - Identifies fabricated facts in outputs
- **Quality Analysis** - Catches off-topic or incomplete responses
- **Loop Detection** - Alerts when agents get stuck repeating themselves
- **Content Safety** - Flags inappropriate or unsafe content

### Signals & Feedback

Capture user feedback and custom metrics directly tied to your traces:

- Thumbs up/down ratings
- Star ratings
- Sentiment analysis
- Goal completion tracking
- Custom metrics

## Quick Links

<CardGroup cols={2}>
  <Card title="Quickstart" icon="rocket" href="/quickstart">
    Get up and running in 5 minutes
  </Card>
  <Card title="JavaScript SDK" icon="js" href="/sdks/javascript/installation">
    Full-featured SDK with tracing support
  </Card>
  <Card title="Python SDK" icon="python" href="/sdks/python/installation">
    Lightweight SDK for Python apps
  </Card>
  <Card title="API Reference" icon="code" href="/api-reference/introduction">
    Complete REST API documentation
  </Card>
</CardGroup>
